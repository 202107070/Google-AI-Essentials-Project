*AI 사용자 - AI를 활용하여 개인적 또는 전문적인 작업을 수행하는 사람

*구조적 편향(Systemic bias) - 특정 결과나 그룹을 선호하거나 기피하는 기관에 의해 지지되는 경향

*데이터 편향(Data bias) - 구조적 오류나 편견이 부당하거나 부정확한 정보로 이어져 편향된 출력을 초래하는 상황

*할당 피해 - AI 시스템의 사용이나 동작이  개인의 웰빙에 영형을 미치는 영역에서 기회나 자원 또는 정보를 차단할 때 발생하는 잘못된 행위

*대표적 피해 - AI 도구가 사람들의 정체성에 기반해 사회 집단의 종속을 강화하는 피해

*소셜 시스템 피해(Social system harm) - AI 도구의 개발 또는 사용의 결과로 기존의 계급, 권력, 또는 특권 불균형이 증폭되거나
신체적 피해가 발생하는 거시적 수준의 사회적 영향

*딥페이크 - 실제 사람이 하지 않은 것을 말하거나 행동하고 있는 AI가 생성한 가짜 사진 또는 동영상

*대인 관계 피해(Interpersonal harm) - 기술을 사용하여 특정인에게 불이익을 주어 다른 사람과의 관계에 부정적인 영향을 미치거나
자아의식과 주체성을 상실하게 하는 피해

*개인 정보 보호 - 사용자가 자신의 개인 정보와 데이터가 수집, 저장, 사용되는 방식을 통제할 수 있는 권리

*보안 - 개인 정보를 보호하고 비공개 데이터를 보호하며 무단 엑세스를 방지하여 시스템 안전을 보장하는 행위

*편향된 출력은 사람과 사회에 다음과 같은 여러 유형의 피해를 줄 수 있습니다.

할당 피해: AI 시스템의 사용이나 동작이 사람의 웰빙에 영향을 미치는 분야에서 기회나 리소스, 정보를 제공하지 않을 때 발생하는 잘못된 동작

예: 어느 아파트 단지의 자산 관리자가 신원 조회를 수행하는 AI 도구를 사용하여 잠재적 입주자의 지원서를 선별하는 경우, AI 도구가 지원자를 잘못 식별하여 지원자의 신용 점수가 낮아 위험 요소가 있다고 판단할 수 있습니다. 그러면 지원자는 아파트 입주를 거절당하고 신청 수수료를 허비하게 될 수 있습니다.

완화하는 방법: 작업에 반영하거나 다른 사람과 공유하기 전에 모든 AI 생성 콘텐츠를 평가합니다. 예시의 상황은 AI 출력을 다른 출처와 대조해 다시 확인하면 방지할 수 있습니다.

서비스 품질 피해: 정체성에 기반한 특정 그룹에 대해 AI 도구가 제대로 작동하지 않는 상황

예: 음성 인식 기술이 처음 개발되던 당시에는 학습 데이터에 장애인의 특성을 나타내는 음성 패턴 예시가 많지 않아서, 기기가 이러한 유형의 음성을 파싱하는 데 어려움을 겪는 경우가 많았습니다.

완화하는 방법: 프롬프트에 포용적인 언어를 추가하여 다양성을 명시합니다. 생성형 AI 도구가 장애인과 같은 특정 집단이나 정체성을 고려하지 못하는 경우 프롬프트를 반복 작성하는 과정에서 해당 문제를 해결합니다.

대표성 피해: AI 도구가 정체성에 기반한 사회 집단의 종속성을 강화함

예: 번역 기술이 처음 개발되던 당시에는 특정 출력이 남성적이거나 여성적인 방향으로 부정확하게 왜곡되기도 했습니다. 예를 들어 '간호사' 및 '아름다운' 같은 단어에 대한 번역을 생성하면 번역이 여성스럽게 왜곡되는 경우가 있었습니다. 반면에 '의사', '강한' 같은 단어를 입력으로 사용되면 남성적인 방향으로 왜곡되었습니다.

완화하는 방법: 가정에 의한 내용을 최소화합니다. 생성형 AI 도구가 남성적으로 또는 여성적으로 왜곡하는 등의 편향된 응답을 출력으로 제공하는 경우, 프롬프트를 반복 작성하는 과정에서 문제를 파악하여 해결하고 편향성을 수정하도록 도구에 요청합니다.

소셜 시스템 피해: AI 도구를 개발하거나 사용한 결과로 인해, 기존의 계급, 권력 또는 특권 불균형을 증폭하거나 물리적 피해를 초래하는 거시적 수준의 사회적 영향

예: 원치 않는 딥페이크, 즉, 현실의 인물이 실제로 하지 않은 말이나 행동이 AI로 생성된 가짜 사진 또는 동영상으로, 소셜 시스템 피해의 한 예시입니다.

완화하는 방법: 출력 내용을 교차 참조하고 사실 여부를 확인합니다. 어떤 생성형 AI 도구에는 정보가 발견된 출처를 제공하는 기능이 있습니다. 검색 엔진을 사용하여 정보를 확인하거나 전문가에게 도움을 요청하는 방법으로 출력의 사실 여부를 확인할 수도 있습니다. 둘 이상의 리소스를 통해 프롬프트를 실행하면 정확성이 떨어지는 출력을 식별하는 데 도움이 됩니다. 

대인 관계 피해: 특정인에게 불이익이 발생하도록 기술을 사용하여 타인과의 관계에 부정적인 영향을 미치거나 자아의식과 주체성의 상실을 초래하는 행위

예: 누군가 이전에 살던 아파트의 홈 기기를 제어할 수 있어 예전 룸메이트에게 원치 않는 짓궂은 장난을 하는 경우, 이러한 행동으로 짓궂은 장난을 당한 사람이 자아의식과 주체성을 상실하는 결과가 발생할 수도 있습니다.

완화하는 방법: AI 사용에 따른 영향을 고려하고 항상 최선으로 판단하고 비판적으로 사고하도록 노력합니다. 현재 수행하는 작업에 AI 사용이 적합한지 자문해 봅니다. 다른 기술과 마찬가지로 AI도 사용하는 방법에 따라 유익하거나 해로울 수 있습니다. 궁극적으로 AI 사용으로 인해 피해를 입지 않도록 하는 것은 사용자의 책임입니다.

*드리프트는 부당하거나 부정확한 출력을 유발할 수 있는 또 다른 현상입니다. 드리프트는 학습 데이터에 반영되지 않은 시간 경과에 따른 변화로 인해 AI 모델의 예측 정확성이 떨어지는 현상입니다. 이 현상은 일반적으로 특정 시점에 모델이 학습되어 해당 날짜 이후의 이벤트나 정보에 대한 지식이 없다는 개념인 지식 단절로 인해 발생합니다. 